{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0Ej_bXyQvnV"
   },
   "source": [
    "# Compute performance metrics for the given Y and Y_score without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# other than these two you should not import any other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KbsWXuDaQvnq"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WaFLW7oBQvnt"
   },
   "outputs": [],
   "source": [
    "def conf_mat(input_arr, prob_arr):\n",
    "    conf_arr = [[0, 0], [0, 0]]\n",
    "    i=0\n",
    "    for j in input_arr:\n",
    "        if int(j) == 1:\n",
    "            if int(prob_arr[i]) == 0:\n",
    "                conf_arr[0][1] = conf_arr[0][1] + 1\n",
    "                i = i+1\n",
    "            else:\n",
    "                conf_arr[0][0] = conf_arr[0][0] + 1\n",
    "                i = i+1\n",
    "        elif int(j) == 0:\n",
    "            if int(prob_arr[i]) == 1:\n",
    "                conf_arr[1][0] = conf_arr[1][0] +1\n",
    "                i = i+1\n",
    "            else:\n",
    "                conf_arr[1][1] = conf_arr[1][1] +1\n",
    "                i = i+1\n",
    "    A = conf_arr[0][0] + conf_arr[1][1]\n",
    "    B = len(input_arr)\n",
    "    acc = A/B                              \n",
    "    accuracy = int(conf_arr[0][0] + conf_arr[1][1])/(len(input_arr))\n",
    "    return acc, conf_arr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10000, 0], [100, 0]]\n",
      "Accuracy:0.9900990099009901\n",
      "F1_score:0.9950248756218906\n",
      "AUC_Score:-0.5\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('5_a.csv')\n",
    "df1 = df.drop(['proba'],axis=1)\n",
    "df2 = df.drop(['y'],axis=1)\n",
    "df2.loc[df2['proba'] > 0.5, 'proba'] = 1\n",
    "df2.loc[df2['proba'] < 0.5, 'proba'] = 0\n",
    "#df.loc[df['proba'] >= 0.5]\n",
    "#df.values.flatten()\n",
    "m = df1.to_numpy()\n",
    "n = df2.to_numpy()\n",
    "#X = np.hsplit(m, 1)\n",
    "M = m.reshape(-1)\n",
    "N = n.reshape(-1)\n",
    "#Y = np.hsplit(m, [1, 2])\n",
    "accuracy, conf_matrix = conf_mat(M,N)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print('Accuracy:{}'.format(accuracy))\n",
    "Score = F1_score(conf_matrix)\n",
    "print('F1_score:{}'.format(Score))\n",
    "tpr, fpr = roc_curve(M,N)\n",
    "X = np.trapz(tpr, fpr)\n",
    "print('AUC_Score:{}'.format(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(conf_matrix):\n",
    "    A = conf_matrix[0][0] + conf_matrix[0][1]\n",
    "    B = conf_matrix[0][0]\n",
    "    precision = B/A\n",
    "    #print(A)\n",
    "    #print(precision)\n",
    "    recall = (conf_matrix[0][0]/(conf_matrix[0][0] + conf_matrix[1][0]))\n",
    "    #print(recall)\n",
    "    f1 = ((2 * precision * recall)/(precision + recall))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve(y_true, y_pred):\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "    thresholds = np.arange(0.0, 1.01, .02)\n",
    "\n",
    "    P = sum(y_true)\n",
    "    N = len(y_true) - P\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        FP=0\n",
    "        TP=0\n",
    "        for y_t,y_p in zip(y_true, y_pred):\n",
    "            if y_p > thresh:\n",
    "                if y_t == 1:\n",
    "                    TP = TP + 1\n",
    "                else:\n",
    "                    FP = FP + 1\n",
    "        fpr.append(FP/float(N))\n",
    "        tpr.append(TP/float(P))\n",
    "    # plt.plot(fpr, tpr)\n",
    "    return tpr, fpr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5KZem1BQvn2"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>B.</b></font> Compute performance metrics for the given data <strong>5_b.csv</strong>\n",
    "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
    "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "<pre>\n",
    "<ol>\n",
    "<li> Compute Confusion Matrix </li>\n",
    "<li> Compute F1 Score </li>\n",
    "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a></li>\n",
    "<li> Compute Accuracy Score </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2sKlq0YQvn5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[55, 45], [239, 9761]]\n",
      "Accuracy:0.9718811881188119\n",
      "F1_score:0.2791878172588833\n",
      "AUC_Score:-0.006572500000000001\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('5_b.csv')\n",
    "df1 = df.drop(['proba'],axis=1)\n",
    "df2 = df.drop(['y'],axis=1)\n",
    "df2.loc[df2['proba'] > 0.5, 'proba'] = 1\n",
    "df2.loc[df2['proba'] < 0.5, 'proba'] = 0\n",
    "#df.loc[df['proba'] >= 0.5]\n",
    "#df.values.flatten()\n",
    "m = df1.to_numpy()\n",
    "n = df2.to_numpy()\n",
    "#X = np.hsplit(m, 1)\n",
    "M = m.reshape(-1)\n",
    "N = n.reshape(-1)\n",
    "#Y = np.hsplit(m, [1, 2])\n",
    "accuracy, conf_matrix = conf_mat(M,N)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print('Accuracy:{}'.format(accuracy))\n",
    "Score = F1_score(conf_matrix)\n",
    "print('F1_score:{}'.format(Score))\n",
    "tpr, fpr = roc_curve(M,N)\n",
    "X = np.trapz(tpr, fpr)\n",
    "print('AUC_Score:{}'.format(X)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GiPGonTzQvoB"
   },
   "source": [
    "<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data <strong>5_c.csv</strong>\n",
    "<br>\n",
    "\n",
    "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
    "\n",
    "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
    "\n",
    "<pre>\n",
    "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
    "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5HIJzq1QvoE"
   },
   "outputs": [],
   "source": [
    " # write your code\n",
    "    \n",
    "def roc_curve(y_true, y_pred):\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "    new = []\n",
    "    X = []\n",
    "    Y = []\n",
    "    i = 0\n",
    "    thresholds = np.arange(0.0, 1.01, .01)\n",
    "\n",
    "    P = sum(y_true)\n",
    "    N = len(y_true) - P\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        FP=0\n",
    "        FN=0\n",
    "        for y_t, y_p in zip(y_true, y_pred):\n",
    "            if y_p < thresh:\n",
    "                if y_t == 1:\n",
    "                    FP = FP + 1\n",
    "            else:\n",
    "                if y_t == 1:\n",
    "                    FN = FN + 1\n",
    "        #i = i+1            \n",
    "        A = (500*FN) + (100*FP)\n",
    "        Y.append(A)\n",
    "        X.append(thresh)\n",
    "    # plt.plot(fpr, tpr)\n",
    "    return Y,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:0.96 value:104700\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('5_c.csv')\n",
    "df1 = df.drop(['prob'],axis=1)\n",
    "df2 = df.drop(['y'],axis=1)\n",
    "#df2.loc[df2['prob'] > 0.5, 'prob'] = 1\n",
    "#df2.loc[df2['prob'] < 0.5, 'prob'] = 0\n",
    "#df.loc[df['proba'] >= 0.5]\n",
    "#df.values.flatten()\n",
    "m = df1.to_numpy()\n",
    "n = df2.to_numpy()\n",
    "#X = np.hsplit(m, 1)\n",
    "M = m.reshape(-1)\n",
    "N = n.reshape(-1)\n",
    "score, threshold = roc_curve(M,N)\n",
    "result = dict(zip(threshold, score))\n",
    "maximum = min(result, key=result.get)\n",
    "print('Threshold:{} value:{}'.format(maximum, result[maximum]))\n",
    "res = \"\\n\".join(\"{} {}\".format(x, y) for x, y in zip(score, threshold))\n",
    "#print(\"Complete result\\n\", res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 177.16569974554707\n",
      "MAPE: 28.199462330815688\n",
      "R-Squared: 0.9563600409880475\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('5_d.csv')\n",
    "#df.head()\n",
    "df1 = df.drop(['pred'],axis=1)\n",
    "df2 = df.drop(['y'],axis=1)\n",
    "m = df1.to_numpy()\n",
    "n = df2.to_numpy()\n",
    "#X = np.hsplit(m, 1)\n",
    "M = m.reshape(-1)\n",
    "N = n.reshape(-1)\n",
    "mse = np.square(np.subtract(M, N)).mean()\n",
    "mape = np.mean(np.abs(percentage_error(np.asarray(M), np.asarray(N)))) * 100\n",
    "r2 = r_square(M,N)\n",
    "print(\"Mean squared error:\", mse)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"R-Squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y   pred\n",
       "0  101.0  100.0\n",
       "1  120.0  100.0\n",
       "2  131.0  113.0\n",
       "3  164.0  125.0\n",
       "4  154.0  152.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('5_d.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_error(actual, predicted):\n",
    "    res = np.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_square(x_values,y_values):\n",
    "    correlation_matrix = np.corrcoef(x_values, y_values)\n",
    "    correlation_xy = correlation_matrix[0,1]\n",
    "    r_squared = correlation_xy**2\n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sD4CcgjXQvoL"
   },
   "source": [
    "<pre>\n",
    "<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n",
    "    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
    "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
    "<ol>\n",
    "<li> Compute Mean Square Error </li>\n",
    "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
    "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
    "</ol>\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
